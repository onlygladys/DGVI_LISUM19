{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 6-TASK\n",
    "\n",
    "File Ingestion and Schema Validation:\n",
    "Take any csv/text file of 2+ GB of your choice. --- (You can do this assignment on Google colab)\n",
    "\n",
    "Read the file ( Present approach of reading the file )\n",
    "\n",
    "Try different methods of file reading eg: Dask, Modin, Ray, pandas and present your findings in term of computational efficiency\n",
    "\n",
    "Perform basic validation on data columns : eg: remove special character , white spaces from the col name\n",
    "\n",
    "As you already know the schema hence create a YAML file and write the column name in YAML file. --define separator of read and write file, column name in YAML\n",
    "\n",
    "Validate number of columns and column name of ingested file with YAML.\n",
    "\n",
    "Write the file in pipe separated text file (|) in gz format.\n",
    "\n",
    "Create a summary of the file:\n",
    "\n",
    "Total number of rows,\n",
    "\n",
    "total number of columns\n",
    "\n",
    "file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6927930"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the size of the raw file:\n",
    "os.path.getsize(r\"D:\\DataGlacier\\Week6\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.607 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "file_path1 = r\"D:\\DataGlacier\\Week6\\test.csv\"\n",
    "\n",
    "def get_size(file_path1, unit='bytes'):\n",
    "    file_size = os.path.getsize(file_path1)\n",
    "    exponents_map = {'bytes': 0, 'kb': 1, 'mb': 2, 'gb': 3}\n",
    "    if unit not in exponents_map:\n",
    "        raise ValueError(\"Must select from \\\n",
    "        ['bytes', 'kb', 'mb', 'gb']\")\n",
    "    else:\n",
    "        size = file_size / 1024 ** exponents_map[unit]\n",
    "        return round(size, 3)\n",
    "\n",
    "\n",
    "print(get_size(file_path1,'mb'),'MB')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the files with various approaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import csv\n",
    "with open(r\"D:\\DataGlacier\\Week6\\test.csv\") as csvfile:  \n",
    "    df = csv.DictReader(csvfile)\n",
    "start_time = time.time()\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictReader takes 0.00800013542175293 seconds\n"
     ]
    }
   ],
   "source": [
    "#Read with DictReader\n",
    "\n",
    "star_time=time.time()\n",
    "dfdict = csv.DictReader(open(r\"D:\\DataGlacier\\Week6\\test.csv\"))\n",
    "a=(\"DictReader takes %s seconds\" % (time.time() - start_time))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas takes 0.23427867889404297 seconds\n"
     ]
    }
   ],
   "source": [
    "#Read with Pandas\n",
    "\n",
    "import pandas as pd\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "dfpandas = pd.read_csv(open(r\"D:\\DataGlacier\\Week6\\test.csv\"))\n",
    "b=(\"Pandas takes %s seconds\" % (time.time() - start_time))\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DaskDataframe takes 0.015623092651367188 seconds\n"
     ]
    }
   ],
   "source": [
    "#Read with Dask\n",
    "\n",
    "import dask.dataframe\n",
    "start_time=time.time()\n",
    "dfdask = dask.dataframe.read_csv(r\"D:\\DataGlacier\\Week6\\test.csv\")\n",
    "c=(\"DaskDataframe takes %s seconds\" % (time.time() - start_time))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 16:36:43,362\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modin and Ray takes 0.546745777130127 seconds\n"
     ]
    }
   ],
   "source": [
    "import modin.pandas as pd\n",
    "import ray\n",
    "ray.shutdown()\n",
    "ray.init(runtime_env={'env_vars': {'__MODIN_AUTOIMPORT_PANDAS__': '1'}})\n",
    "start_time=time.time()\n",
    "dfmod=pd.read_csv(r\"D:\\DataGlacier\\Week6\\test.csv\",chunksize=200000)\n",
    "for chunksize in dfmod:\n",
    "#print(chunksize)\n",
    " d=(\"Modin and Ray takes %s seconds\" % (time.time() - start_time))\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DictReader takes 0.00800013542175293 seconds\n",
      "Pandas takes 0.23427867889404297 seconds\n",
      "DaskDataframe takes 0.015623092651367188 seconds\n",
      "Modin and Ray takes 0.546745777130127 seconds\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The least time taken to read a csv file is:  DaskDataframe takes 0.015623092651367188 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"The least time taken to read a csv file is: \", min(a,b,c,d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe\n",
    "df= dask.dataframe.read_csv(r\"D:\\DataGlacier\\Week6\\test.csv\",delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dask.dataframe.core.DataFrame'>\n",
      "Columns: 11 entries, id to Vintage\n",
      "dtypes: object(3), float64(3), int64(5)"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: describe-numeric, 51 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                    id      Age Driving_License Region_Code Previously_Insured Annual_Premium Policy_Sales_Channel  Vintage\n",
       "npartitions=1                                                                                                              \n",
       "               float64  float64         float64     float64            float64        float64              float64  float64\n",
       "                   ...      ...             ...         ...                ...            ...                  ...      ...\n",
       "Dask Name: describe-numeric, 51 tasks"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove special characters\n",
    "df.columns=df.columns.str.replace('[#,@,&,_]','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove white space from columns\n",
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Gender', 'Age', 'DrivingLicense', 'RegionCode',\n",
       "       'PreviouslyInsured', 'VehicleAge', 'VehicleDamage', 'AnnualPremium',\n",
       "       'PolicySalesChannel', 'Vintage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdfdask=df.columns\n",
    "newdfdask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting testutility.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile testutility.py\n",
    "import logging\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import datetime \n",
    "import gc\n",
    "import re\n",
    "\n",
    "\n",
    "def read_config_file(filepath):\n",
    "    with open(filepath, 'r') as stream:\n",
    "        try:\n",
    "            return yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            logging.error(exc)\n",
    "\n",
    "\n",
    "def replacer(string, char):\n",
    "    pattern = char + '{2,}'\n",
    "    string = re.sub(pattern, char, string) \n",
    "    return string\n",
    "\n",
    "def col_header_val(df,table_config):\n",
    "    '''\n",
    "    replace whitespaces in the column\n",
    "    and standardized column names\n",
    "    '''\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace('[^\\w]','_',regex=True)\n",
    "    df.columns = list(map(lambda x: x.strip('_'), list(df.columns)))\n",
    "    df.columns = list(map(lambda x: replacer(x,'_'), list(df.columns)))\n",
    "    expected_col = list(map(lambda x: x.lower(),  table_config['columns']))\n",
    "    expected_col.sort()\n",
    "    df.columns =list(map(lambda x: x.lower(), list(df.columns)))\n",
    "    df = df.reindex(sorted(df.columns), axis=1)\n",
    "    if len(df.columns) == len(expected_col) and list(expected_col)  == list(df.columns):\n",
    "        print(\"column name and column length validation passed\")\n",
    "        return 1\n",
    "    else:\n",
    "        print(\"column name and column length validation failed\")\n",
    "        mismatched_columns_file = list(set(df.columns).difference(expected_col))\n",
    "        print(\"Following File columns are not in the YAML file\",mismatched_columns_file)\n",
    "        missing_YAML_file = list(set(expected_col).difference(df.columns))\n",
    "        print(\"Following YAML columns are not in the file uploaded\",missing_YAML_file)\n",
    "        logging.info(f'df columns: {df.columns}')\n",
    "        logging.info(f'expected columns: {expected_col}')\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting file.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile file.yaml\n",
    "file_type: csv\n",
    "dataset_name: testfile\n",
    "file_name: test\n",
    "table_name: edsurv\n",
    "inbound_delimiter: \",\"\n",
    "outbound_delimiter: \"|\"\n",
    "skip_leading_rows: 1\n",
    "columns:\n",
    "     -id\n",
    "     -Gender\n",
    "     -Age \n",
    "     -DrivingLicense \n",
    "     -RegionCode\n",
    "     -PreviouslyInsured\n",
    "     -VehicleAge\n",
    "     -VehicleDamage\n",
    "     -AnnualPremium\n",
    "     -PolicySalesChannel \n",
    "     -Vintage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading config file\n",
    "\n",
    "import testutility as util\n",
    "config_data = util.read_config_file('file.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "','"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data of config file\n",
    "config_data['inbound_delimiter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_type': 'csv',\n",
       " 'dataset_name': 'testfile',\n",
       " 'file_name': 'test',\n",
       " 'table_name': 'edsurv',\n",
       " 'inbound_delimiter': ',',\n",
       " 'outbound_delimiter': '|',\n",
       " 'skip_leading_rows': 1,\n",
       " 'columns': '-id -Gender -Age -DrivingLicense -RegionCode -PreviouslyInsured -VehicleAge -VehicleDamage -AnnualPremium -PolicySalesChannel -Vintage'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381110</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>35786.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381111</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33762.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>381112</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40050.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381113</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37356.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>381114</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>59097.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0  381110   Male   25                1         11.0                   1   \n",
       "1  381111   Male   40                1         28.0                   0   \n",
       "2  381112   Male   47                1         28.0                   0   \n",
       "3  381113   Male   24                1         27.0                   1   \n",
       "4  381114   Male   27                1         28.0                   1   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \n",
       "0    < 1 Year             No         35786.0                 152.0       53  \n",
       "1    1-2 Year            Yes         33762.0                   7.0      111  \n",
       "2    1-2 Year            Yes         40050.0                 124.0      199  \n",
       "3    < 1 Year            Yes         37356.0                 152.0      187  \n",
       "4    < 1 Year             No         59097.0                 152.0      297  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading process of the file using Dask\n",
    "from dask import dataframe as dd\n",
    "df_sample = dd.read_csv(r\"D:\\DataGlacier\\Week6\\test.csv\",delimiter=',')\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the file using config file\n",
    "file_type = config_data['file_type']\n",
    "#source_file = \"D:/DataGlacier/Week6/\" + config_data['file_name'] + f'.{file_type}'\n",
    "source_file=\"./\" + config_data['file_name'] + f'.{file_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Driving_License</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Previously_Insured</th>\n",
       "      <th>Vehicle_Age</th>\n",
       "      <th>Vehicle_Damage</th>\n",
       "      <th>Annual_Premium</th>\n",
       "      <th>Policy_Sales_Channel</th>\n",
       "      <th>Vintage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>381110</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>35786.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>381111</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>33762.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>381112</td>\n",
       "      <td>Male</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40050.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381113</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>37356.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>381114</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt; 1 Year</td>\n",
       "      <td>No</td>\n",
       "      <td>59097.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id Gender  Age  Driving_License  Region_Code  Previously_Insured  \\\n",
       "0  381110   Male   25                1         11.0                   1   \n",
       "1  381111   Male   40                1         28.0                   0   \n",
       "2  381112   Male   47                1         28.0                   0   \n",
       "3  381113   Male   24                1         27.0                   1   \n",
       "4  381114   Male   27                1         28.0                   1   \n",
       "\n",
       "  Vehicle_Age Vehicle_Damage  Annual_Premium  Policy_Sales_Channel  Vintage  \n",
       "0    < 1 Year             No         35786.0                 152.0       53  \n",
       "1    1-2 Year            Yes         33762.0                   7.0      111  \n",
       "2    1-2 Year            Yes         40050.0                 124.0      199  \n",
       "3    < 1 Year            Yes         37356.0                 152.0      187  \n",
       "4    < 1 Year             No         59097.0                 152.0      297  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(source_file,config_data['inbound_delimiter'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation failed\n",
      "Following File columns are not in the YAML file ['policy_sales_channel', 'vintage', 'vehicle_age', 'id', 'age', 'previously_insured', 'region_code', 'annual_premium', 'gender', 'driving_license', 'vehicle_damage']\n",
      "Following YAML columns are not in the file uploaded ['c', 'v', 's', 'g', 'n', 'y', 'd', 'e', 'p', ' ', 'r', 'u', 'a', 'h', '-', 'm', 'l', 'i', 't', 'o']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#validating the header of the file\n",
    "util.col_header_val(df,config_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns of files are: Index(['id', 'gender', 'age', 'driving_license', 'region_code',\n",
      "       'previously_insured', 'vehicle_age', 'vehicle_damage', 'annual_premium',\n",
      "       'policy_sales_channel', 'vintage'],\n",
      "      dtype='object')\n",
      "columns of YAML are: -id -Gender -Age -DrivingLicense -RegionCode -PreviouslyInsured -VehicleAge -VehicleDamage -AnnualPremium -PolicySalesChannel -Vintage\n"
     ]
    }
   ],
   "source": [
    "print(\"columns of files are:\" ,df.columns)\n",
    "print(\"columns of YAML are:\" ,config_data['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation failed\n",
      "Following File columns are not in the YAML file ['policy_sales_channel', 'vintage', 'vehicle_age', 'id', 'age', 'previously_insured', 'region_code', 'annual_premium', 'gender', 'driving_license', 'vehicle_damage']\n",
      "Following YAML columns are not in the file uploaded ['c', 'v', 's', 'g', 'n', 'y', 'd', 'e', 'p', ' ', 'r', 'u', 'a', 'h', '-', 'm', 'l', 'i', 't', 'o']\n",
      "validation failed\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if util.col_header_val(df,config_data)==0:\n",
    "    print(\"validation failed\")\n",
    "else:\n",
    "    print(\"col validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/NammaPC/File ingestion and schema validation/test.csv.gz\\\\0.part']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import csv\n",
    "import gzip\n",
    "\n",
    "from dask import dataframe as dd\n",
    "df = dd.read_csv(r'D:\\DataGlacier\\Week6\\test.csv',delimiter=',')\n",
    "\n",
    "# Write csv in gz format in pipe separated text file (|)\n",
    "df.to_csv('test.csv.gz',\n",
    "          sep='|',\n",
    "          header=True,\n",
    "          index=False,\n",
    "          quoting=csv.QUOTE_ALL,\n",
    "          compression='gzip',\n",
    "          quotechar='\"',\n",
    "          doublequote=True,\n",
    "          line_terminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.part\n"
     ]
    }
   ],
   "source": [
    "#number of files in gz format folder\n",
    "import os\n",
    "entries = os.listdir(r'C:/Users/NammaPC/File ingestion and schema validation/test.csv.gz')\n",
    "for entry in entries:\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1541258"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of the gz format folder\n",
    "a=os.path.getsize(r'C:\\Users\\NammaPC\\File ingestion and schema validation/test.csv.gz\\\\0.part')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = r'C:\\Users\\NammaPC\\File ingestion and schema validation/test.csv.gz\\\\0.part'\n",
    "\n",
    "def get_size(file_path, unit='bytes'):\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    exponents_map = {'bytes': 0, 'kb': 1, 'mb': 2, 'gb': 3}\n",
    "    if unit not in exponents_map:\n",
    "        raise ValueError(\"Must select from \\\n",
    "        ['bytes', 'kb', 'mb', 'gb']\")\n",
    "    else:\n",
    "        size = file_size / 1024 ** exponents_map[unit]\n",
    "        return round(size, 3)\n",
    "\n",
    "\n",
    "sizeoffile=(get_size(file_path,'mb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "Total number of rows are: 127037\n",
      "Total number of columns are : 11\n",
      "Size of the file is 1.47 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary:\")\n",
    "\n",
    "# Total number of observations:\n",
    "print(\"Total number of rows are:\",len(df))\n",
    "\n",
    "# Total number of features:\n",
    "print(\"Total number of columns are :\",len(df.columns))\n",
    "df.columns\n",
    "\n",
    "print(\"Size of the file is\",sizeoffile,\"MB\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
